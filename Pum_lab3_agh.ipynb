{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rttMWigaqHiF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.datasets as sk_ds\n",
    "import sklearn.svm as sk_svm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sIyjhUAs3645",
    "outputId": "80d76954-2013-4e2f-b2a4-500b2089d9c1"
   },
   "outputs": [],
   "source": [
    "wbc_features, wbc_targets = sk_ds.load_breast_cancer(True)\n",
    "print('WBC: Zbiór {} danych z {} cechami'.format(len(wbc_targets),\n",
    "                                                 wbc_features.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k39TzniRskcm"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-zWtKtHuYGc"
   },
   "source": [
    "### Klasyfikator liniowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ON5q8fk1xRxR"
   },
   "source": [
    "$$ y = f(\\vec{w} \\cdot \\vec{x}) = f(\\sum_i w_i x_i)  $$\n",
    "\n",
    "$\\vec{w}$ - wektor wag klasyfikatora\n",
    "\n",
    "$\\vec{x}$ - wektor wejściowy cech\n",
    "\n",
    "$f$ - funkcja decyzyjna $\\Re \\to N $ odwzorowuje zbiór liczb rzeczywistych na klasę \n",
    "\n",
    "Dla dwóch klas funkcja $f$ zazwyczaj przypisuje iloczyn skalarny do jednej klasy jeśli jest on większy od pewnej wartości i do drugiej klasy jeśli nie jest. W takim przypadku klasyfikator liniowy dzieli przestrzeń wejściową za pomocą hiperpłaszczyzny, czyli uogólnienia płaszczyzny do n-wymiarów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "BMRzEM2y1ZAB",
    "outputId": "debc0163-99a4-446e-f5b0-5607ebd41a2e"
   },
   "outputs": [],
   "source": [
    "def make_linear():\n",
    "  in_features = wbc_features[40:70,:2]\n",
    "  out_targets = wbc_targets[40:70]\n",
    "  \n",
    "  min_x = in_features[:,0].min() - 1\n",
    "  max_x = in_features[:,0].max() + 1\n",
    "  min_y = in_features[:,1].min() - 1\n",
    "  max_y = in_features[:,1].max() + 1\n",
    "  xx, yy = np.meshgrid(np.arange(min_x, max_x, 0.01),\n",
    "                       np.arange(min_y, max_y, 0.01))\n",
    "  classifier = sk_svm.LinearSVC(dual=False, tol=0.0000001)\n",
    "  classifier.fit(in_features, out_targets)\n",
    "  Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "  Z = Z.reshape(xx.shape)\n",
    "  plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "  plt.scatter(in_features[:,0], in_features[:,1], c=out_targets, cmap=plt.cm.coolwarm)\n",
    "  plt.show()\n",
    "  \n",
    "make_linear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q86C89Pwub_S"
   },
   "source": [
    "### Klasyfikator SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR8FkdQYuhhL"
   },
   "source": [
    "### Trik kernelowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OklztgToulNM"
   },
   "source": [
    "### Jakość klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC - Receiver Operating Characteristic \n",
    "Krzywa ROC służy do oceny jakości klasyfikatora. Przedstawia zależność ilości prawdziwie pozytywnych ($T_p$) i fałszywie pozytywnych wyników ($T_f$). Krzywa idealnego klasyfikatora obejmuje lewy górny punkt wykresu (100% prawdziwie pozytywnych wyników i 0% fałszywie pozytywnych), zatem zazwyczaj większe pole pod wykresem jest lepsze. Istotne jest także nachylenie wykresu, bardziej stromy jest lepszy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "\n",
    "indices = y < 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[indices], y[indices], test_size=0.5, random_state=2)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "probs = classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "area_under_curve = roc_auc_score(y_test, probs)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='no skill')\n",
    "plt.plot(false_positive_rate, true_positive_rate, marker='.', label='ROC curve (area = {0:.2f})'.format(area_under_curve))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('T_f (false positive rate)')\n",
    "plt.ylabel('T_p (true positive rate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall\n",
    "Miara precision-recall służy do określania jakości klasyfikatora, szczególnie jeżeli liczebność obu klas znacznie się różni. Składa się z dwóch parametrów:\n",
    "* **precision** ($P$): stosunek liczby prawdziwie pozytywnych wskazań ($T_p$) do liczby prawdziwie pozytywnych i fałszywie pozytywnych wskazań klasyfikatora ($T_p + T_f$)\n",
    "$$ P = \\frac{T_p}{T_p+T_f}$$\n",
    "* **recall** ($R$): stosunek liczby prawdziwie pozytywnych wskazań ($T_p$) do liczby prawdziwie pozytywnych i fałszywie negatywnych wskazań klasyfikatora ($T_p + F_n$)\n",
    "$$ R = \\frac{T_p}{T_p+F_n}$$\n",
    "Obie wartości zależą od progu klasyfikatora.\n",
    "\n",
    "Zmniejszanie progu może zwiększyć ilość zwróconych wyników ($T_p+T_f$). Jeżeli próg był ustawiony zbyt wysoko, to dodatkowe wyniki będą prawdziwie pozytywne, dzięki czemu zwiększy się precision i recall. Jeżeli próg był odpowiedni lub zbyt niski, to w dodatkowych wynikach będzie dużo fałszywie pozytywnych punktów, przez co spadnie precision, a recall niewiele się zwiększy. Obrazuje to kształt wykresu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "# split into train/test sets, selecting only 2 classes\n",
    "indices = y < 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[indices], y[indices], test_size=0.5, random_state=2)\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "probs = classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = classifier.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "f1 = f1_score(y_test, yhat)\n",
    "area_under_curve = auc(recall, precision)\n",
    "average_precision = average_precision_score(y_test, probs)\n",
    "\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, area_under_curve, average_precision))\n",
    "\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--', label='no skill')\n",
    "plt.plot(recall, precision, marker='.', label='precision-recall curve (area = {0:.2f})'.format(area_under_curve))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('R (recall)')\n",
    "plt.ylabel('P (precision)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1\n",
    "F1 to miara jakości klasyfikatora. Jest średnią harmoniczną wartości precision i recall. Najlepszy klasyfikator ma F1 równy 1, a najgorszy 0.\n",
    "$$F1 = (\\frac{P^{-1} + R^{-1}}{2})^{-1} = 2\\frac{P\\cdotR}{P+}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Różnica między krzywymi ROC i precision-recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as pyplot\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9,0.1], random_state=1)\n",
    "# split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "roc_auc = roc_auc_score(y_test, probs)\n",
    "print('area under ROC curve: %.3f' % roc_auc)\n",
    "# calculate roc curve\n",
    "false_positive_ratio, true_positive_ratio, thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='no skill')\n",
    "plt.plot(false_positive_ratio, true_positive_ratio, marker='.', label='ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('T_f (false positive rate)')\n",
    "plt.ylabel('T_p (true positive rate)')\n",
    "plt.show()\n",
    "\n",
    "# predict class values\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "f1 = f1_score(y_test, yhat)\n",
    "pr_auc = auc(recall, precision)\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, pr_auc, ap))\n",
    "\n",
    "plt.plot([0, 1], [0.1, 0.1], linestyle='--', label='no skill')\n",
    "plt.plot(recall, precision, marker='.', label='precision-recall curve (area = {0:.2f})'.format(area_under_curve))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('R (recall)')\n",
    "plt.ylabel('P (precision)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MYPwMIOswVh"
   },
   "source": [
    "## Działanie SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqlIAdCatOS8"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pum-lab3-agh.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
