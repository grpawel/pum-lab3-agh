{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rttMWigaqHiF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.datasets as sk_ds\n",
    "import sklearn.svm as sk_svm\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sIyjhUAs3645",
    "outputId": "80d76954-2013-4e2f-b2a4-500b2089d9c1"
   },
   "outputs": [],
   "source": [
    "wbc_features, wbc_targets = sk_ds.load_breast_cancer(True)\n",
    "print('WBC: Zbiór {} danych z {} cechami'.format(len(wbc_targets),\n",
    "                                                 wbc_features.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k39TzniRskcm"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-zWtKtHuYGc"
   },
   "source": [
    "### Klasyfikator liniowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ON5q8fk1xRxR"
   },
   "source": [
    "$$ y = f(\\vec{w} \\cdot \\vec{x}) = f(\\sum_i w_i x_i)  $$\n",
    "\n",
    "$\\vec{w}$ - wektor wag klasyfikatora\n",
    "\n",
    "$\\vec{x}$ - wektor wejściowy cech\n",
    "\n",
    "$f$ - funkcja decyzyjna $\\Re \\to N $ odwzorowuje zbiór liczb rzeczywistych na klasę \n",
    "\n",
    "Dla dwóch klas funkcja $f$ zazwyczaj przypisuje iloczyn skalarny do jednej klasy jeśli jest on większy od pewnej wartości i do drugiej klasy jeśli nie jest. W takim przypadku klasyfikator liniowy dzieli przestrzeń wejściową za pomocą hiperpłaszczyzny, czyli uogólnienia płaszczyzny do n-wymiarów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "BMRzEM2y1ZAB",
    "outputId": "debc0163-99a4-446e-f5b0-5607ebd41a2e"
   },
   "outputs": [],
   "source": [
    "def make_linear():\n",
    "  in_features = wbc_features[40:70,:2]\n",
    "  out_targets = wbc_targets[40:70]\n",
    "  \n",
    "  min_x = in_features[:,0].min() - 1\n",
    "  max_x = in_features[:,0].max() + 1\n",
    "  min_y = in_features[:,1].min() - 1\n",
    "  max_y = in_features[:,1].max() + 1\n",
    "  xx, yy = np.meshgrid(np.arange(min_x, max_x, 0.01),\n",
    "                       np.arange(min_y, max_y, 0.01))\n",
    "  classifier = sk_svm.LinearSVC(dual=False, tol=0.0000001)\n",
    "  classifier.fit(in_features, out_targets)\n",
    "  Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "  Z = Z.reshape(xx.shape)\n",
    "  plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "  plt.scatter(in_features[:,0], in_features[:,1], c=out_targets, cmap=plt.cm.coolwarm)\n",
    "  plt.show()\n",
    "  \n",
    "make_linear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q86C89Pwub_S"
   },
   "source": [
    "### Klasyfikator SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "# Dataset and targets\n",
    "X = np.c_[(.4, -.7),(-1.5, -1),(-1.4, -.9),(-1.3, -1.2),(-1.1, -.2),(-1.2, -.4),(-.5, 1.2),(-1.5, 2.1),(1, 1),\n",
    "          (1.3, .8),(1.2, .5),(.2, -2),(.5, -2.4),(.2, -2.3),(0, -2.7),(1.3, 2.1)].T\n",
    "Y = [0] * 8 + [1] * 8\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "for i, kernel in enumerate(['linear', 'poly', 'rbf']):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=2)\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    #plt.figure(i, figsize=(3, 4))\n",
    "    #plt.clf()\n",
    "\n",
    "    axes[i].scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,\n",
    "                facecolors='none', zorder=10, edgecolors='k')\n",
    "    axes[i].scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired,\n",
    "                edgecolors='k')\n",
    "\n",
    "    axes[i].axis('tight')\n",
    "    x_min = -3\n",
    "    x_max = 3\n",
    "    y_min = -3\n",
    "    y_max = 3\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    #axes[i].figure(i, figsize=(3, 4))\n",
    "    axes[i].pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    axes[i].contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    axes[i].set_xlim(x_min, x_max)\n",
    "    axes[i].set_ylim(y_min, y_max)\n",
    "    axes[i].set_xticks(())\n",
    "    axes[i].set_yticks(())\n",
    "    axes[i].set_title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR8FkdQYuhhL"
   },
   "source": [
    "### Trik kernelowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OklztgToulNM"
   },
   "source": [
    "### Jakość klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC - Receiver Operating Characteristic \n",
    "Krzywa ROC służy do oceny jakości klasyfikatora. Przedstawia zależność ilości prawdziwie pozytywnych ($T_p$) i fałszywie pozytywnych wyników ($T_f$). Krzywa idealnego klasyfikatora obejmuje lewy górny punkt wykresu (100% prawdziwie pozytywnych wyników i 0% fałszywie pozytywnych), zatem zazwyczaj większe pole pod wykresem jest lepsze. Istotne jest także nachylenie wykresu, bardziej stromy jest lepszy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "\n",
    "indices = y < 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[indices], y[indices], test_size=0.5, random_state=2)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "probs = classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "area_under_curve = roc_auc_score(y_test, probs)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='no skill')\n",
    "plt.plot(false_positive_rate, true_positive_rate, marker='.', label='ROC curve (area = {0:.2f})'.format(area_under_curve))\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('T_f (false positive rate)')\n",
    "plt.ylabel('T_p (true positive rate)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall\n",
    "Miara precision-recall służy do określania jakości klasyfikatora, szczególnie jeżeli liczebność obu klas znacznie się różni. Składa się z dwóch parametrów:\n",
    "* **precision** ($P$): stosunek liczby prawdziwie pozytywnych wskazań ($T_p$) do liczby prawdziwie pozytywnych i fałszywie pozytywnych wskazań klasyfikatora ($T_p + T_f$)\n",
    "$$ P = \\frac{T_p}{T_p+T_f}$$\n",
    "* **recall** ($R$): stosunek liczby prawdziwie pozytywnych wskazań ($T_p$) do liczby prawdziwie pozytywnych i fałszywie negatywnych wskazań klasyfikatora ($T_p + F_n$)\n",
    "$$ R = \\frac{T_p}{T_p+F_n}$$\n",
    "Obie wartości zależą od progu klasyfikatora.\n",
    "\n",
    "Zmniejszanie progu może zwiększyć ilość zwróconych wyników ($T_p+T_f$). Jeżeli próg był ustawiony zbyt wysoko, to dodatkowe wyniki będą prawdziwie pozytywne, dzięki czemu zwiększy się precision i recall. Jeżeli próg był odpowiedni lub zbyt niski, to w dodatkowych wynikach będzie dużo fałszywie pozytywnych punktów, przez co spadnie precision, a recall niewiele się zwiększy. Obrazuje to kształt wykresu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "# split into train/test sets, selecting only 2 classes\n",
    "indices = y < 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[indices], y[indices], test_size=0.5, random_state=2)\n",
    "\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "probs = classifier.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# predict class values\n",
    "yhat = classifier.predict(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "f1 = f1_score(y_test, yhat)\n",
    "area_under_curve = auc(recall, precision)\n",
    "average_precision = average_precision_score(y_test, probs)\n",
    "\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, area_under_curve, average_precision))\n",
    "\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--', label='no skill')\n",
    "plt.plot(recall, precision, marker='.', label='precision-recall curve (area = {0:.2f})'.format(area_under_curve))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('R (recall)')\n",
    "plt.ylabel('P (precision)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1\n",
    "F1 to miara jakości klasyfikatora. Jest średnią harmoniczną wartości precision i recall. Najlepszy klasyfikator ma F1 równy 1, a najgorszy 0.\n",
    "$$F1 = (\\frac{P^{-1} + R^{-1}}{2})^{-1} = 2\\frac{P\\cdot R}{P+R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Różnica między krzywymi ROC i precision-recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as pyplot\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9,0.1], random_state=1)\n",
    "# split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# fit a model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "roc_auc = roc_auc_score(y_test, probs)\n",
    "print('area under ROC curve: %.3f' % roc_auc)\n",
    "# calculate roc curve\n",
    "false_positive_ratio, true_positive_ratio, thresholds = roc_curve(y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='no skill')\n",
    "plt.plot(false_positive_ratio, true_positive_ratio, marker='.', label='ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('T_f (false positive rate)')\n",
    "plt.ylabel('T_p (true positive rate)')\n",
    "plt.show()\n",
    "\n",
    "# predict class values\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "f1 = f1_score(y_test, yhat)\n",
    "pr_auc = auc(recall, precision)\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, pr_auc, ap))\n",
    "\n",
    "plt.plot([0, 1], [0.1, 0.1], linestyle='--', label='no skill')\n",
    "plt.plot(recall, precision, marker='.', label='precision-recall curve (area = {0:.2f})'.format(area_under_curve))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('R (recall)')\n",
    "plt.ylabel('P (precision)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MYPwMIOswVh"
   },
   "source": [
    "## Działanie SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqlIAdCatOS8"
   },
   "source": [
    "* Dane ze zbioru WBC dzielimy na K podzbiorów\n",
    "* Dla każdego podzbioru trenujemy SVM, pozostałe podzbiory służą do weryfikacji\n",
    "* Obliczamy parametry działania dla każdego z klasyfikatorów z osobna i łączne, dla czałego zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_all_folds(X, y, k_fold, classifier, title):\n",
    "    print(title)\n",
    "    f, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    y_real = []\n",
    "    y_proba = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(k_fold.split(X, y)):\n",
    "        # split dataset\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # train classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        # predict probabilities\n",
    "        proba = classifier.predict_proba(X_test)\n",
    "        proba = proba[:,1]\n",
    "        \n",
    "        # calculate and plot ROC curve\n",
    "        roc_auc = roc_auc_score(y_test, proba)\n",
    "        false_positive_ratio, true_positive_ratio, thresholds = roc_curve(y_test, proba)\n",
    "        roc_label = 'Fold {}: ROC AUC={:.4f}'.format(i+1, roc_auc)\n",
    "        axes[0].step(false_positive_ratio, true_positive_ratio, marker='.', label=roc_label)\n",
    "        \n",
    "        # calculate and plot precision-recall curve, F1 score and average precision\n",
    "        yhat = classifier.predict(X_test)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, proba)\n",
    "        f1 = f1_score(y_test, yhat)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        ap = average_precision_score(y_test, proba)\n",
    "\n",
    "        pr_label = 'Fold {}: PR AUC={:.4f}'.format(i+1, auc(recall, precision))\n",
    "        axes[1].step(recall, precision, marker='.', label=pr_label)\n",
    "    \n",
    "        print('Fold {}: ROC auc={:.4f} f1={:.4f} P-R auc={:.4f} ap={:.4f}'.format(i, roc_auc, f1, pr_auc, ap))\n",
    "        \n",
    "        y_real.append(y_test)\n",
    "        y_proba.append(proba)\n",
    "\n",
    "    # contatenate values from whole dataset\n",
    "    y_real = np.concatenate(y_real)\n",
    "    y_proba = np.concatenate(y_proba)\n",
    "    \n",
    "    # calculate average ROC curve and plot reference value\n",
    "    false_positive_ratio, true_positive_ratio, _ = roc_curve(y_real, y_proba)\n",
    "    roc_label = 'Overall AUC={:.4f} {:.4f}'.format(auc(true_positive_ratio, false_positive_ratio),roc_auc_score(y_real, y_proba) )\n",
    "    axes[0].step(false_positive_ratio, true_positive_ratio, label=roc_label, lw=2, color='black')\n",
    "    axes[0].plot([0, 1], [0, 1], linestyle='--', label='no skill')\n",
    "    \n",
    "    # calculate average precision-recall curve and plot reference value\n",
    "    precision, recall, _ = precision_recall_curve(y_real, y_proba)\n",
    "    pr_label = 'Overall AUC=%.4f' % (auc(recall, precision))\n",
    "    axes[1].step(recall, precision, label=pr_label, lw=2, color='black')\n",
    "    axes[1].plot([0, 1], [0.5, 0.5], linestyle='--', label='no skill')\n",
    "    \n",
    "    axes[0].legend(loc='best', fontsize='small')\n",
    "    axes[0].set_xlabel('T_f (false positive rate)')\n",
    "    axes[0].set_ylabel('T_p (true positive rate)')\n",
    "    axes[1].set_xlabel('R (recall)')\n",
    "    axes[1].set_ylabel('P (precision)')\n",
    "    axes[1].legend(loc='best', fontsize='small')\n",
    "\n",
    "    f.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "FOLDS = 5\n",
    "SAMPLES = 200\n",
    "\n",
    "X = wbc_features[:SAMPLES]\n",
    "y = wbc_targets[:SAMPLES]\n",
    "\n",
    "# prepare classifiers\n",
    "classifiers = [\n",
    "    SVC(gamma='auto', kernel='linear', C=1.0, probability=True, random_state=1),\n",
    "    SVC(gamma=0.001, kernel='rbf', probability=True, random_state=1),\n",
    "    SVC(gamma='auto', kernel='rbf', probability=True, random_state=1),\n",
    "    SVC(gamma='auto', kernel='poly', C=1.0, probability=True, random_state=1),\n",
    "]\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=1)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    title = 'SVC kernel: {}'.format(classifier.kernel)\n",
    "    plot_all_folds(X, y, k_fold, classifier, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wizualizacja wyników za pomocą PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "X = wbc_features[:SAMPLES]\n",
    "y = wbc_targets[:SAMPLES]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "\n",
    "# aplikacja PCA na zbiorze danych X\n",
    "pca.fit(X)\n",
    "X_transformed = pca.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "for classifier in classifiers:\n",
    "\n",
    "    classifier.fit(X, y)\n",
    "    # plot predictions\n",
    "    plt.scatter(X_transformed[y_pred==0, 0], X_transformed[y_pred==0, 1], color='none', edgecolor='darkred', s=50)\n",
    "    plt.scatter(X_transformed[y_pred==1, 0], X_transformed[y_pred==1, 1], color='none', edgecolor='darkblue', s=50)\n",
    "    \n",
    "    # plot expected values\n",
    "    plt.scatter(X_transformed[y==0, 0], X_transformed[y==0, 1], color='red', s=20)\n",
    "    plt.scatter(X_transformed[y==1, 0], X_transformed[y==1, 1], color='blue', s=20)\n",
    "    plt.title(classifier.kernel)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pum-lab3-agh.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
